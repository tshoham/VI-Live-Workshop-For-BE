# Lab 2

## Background
VI Live will need to handle many streams simultaniously, which is one of the benefits of Nvidia's Deepstream.
As we mentioned, Deepstream efficiently processes multiple videos simultaneously.

This lab will highlight multi-stream processing within the pipeline.

In addition, this pipeline will write results to a file - this is what we will most likely use in VI since the BE needs to receive the results and save them. 

## Purpose
lab2.py is a simplification of pipelines that data science team created. 
This example allows for a lot of versatile pipelines. 

We will focus on a simple pipeline that gets input from file sources, and outputs the results to files. In our example, the pipeline will run a detector and tracker. The pipeline will also write insights to a file.

We will write the part of the code that handle multiple inputs.

> [!IMPORTANT]
> In lab1 we used h264 files and had file-source, a parser, and decoder.
> 
> In lab2, the code uses `uridecodebin` so that any type of input (e.g. RTSP/File) that is GStreamer supported container format and any codec can be used as input.
>
> Here the "source" is based on Gst.ElementFactory.make("nvurisrcbin", "uri-decode-bin") and Gst.Bin.
>
> Gst.Bin is a GStreamer container that hides the complexity of internal elements from the pipeline.
> To take a closer look at this code you can checkout the function ```create_source_bin```

## Instructions

1. Write the function `def create_and_link_sources(src_config: SrcConfig, number_sources, streammux, pipeline)` (Look for it in the code and write the implementation)

    The paramenter `src_config` has an array of input_uris `src_config.input_uris`.
    Loop through these uris. 
    
    For each index do the following:

    1. Call function `create_source_bin(src_config, i)`
        - Where i is the index of the loop

    2. Add the source element you created to the pipeline.
    3. Create a sinkpad for the streamux and verify the component. The sinkpad name will be `"sink_i"`.

    > [!TIP]
> Use lab1 readme for the syntax.
    > [!NOTE]
> Pads are interfaces through which data flows in and out of elements.
> An element can have multiple pads, so in this case we have a new pad for each source.
> Pads allow  modularity, flexibility, data flow control, dynamic linking, and compatibility.

    4. create a srcpad for the source element and verify the component (use lab1 readme for syntax)
    
    1. Link srcpad to sinkpad.

    > [!NOTE]
> You are linking each source to a sinkpad of the streammux. Notice how the streamux has one link to the rest of the pipeline.

2. Set the property `batch-size` of the pgie element and for streamumx (look for "Your implementation goes here" in the code)

    1. Set the "batch-size" property of the streammux to the number of sources: `streammux.set_property("batch-size", number_sources)`

    2. Get the current batch size setting by running `pgie.get_property("batch-size")`
    3. Compare the current batch size property to the number_sources. 
    4. If they don't match then set the batch size property of the pgie element to the number of resources.

    > [!NOTE]
> Batch-size can be set in the AI inference configuration, and can also be updated from within the pipeline.
> This is something we will need to update in VI when cameras are added/removed.
